{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction\n",
    "\n",
    "We take the embedded data and calculate the cosine similarity between nodes. Cosine similarity is equal to normalized dot product similarity (source: https://zhang-yang.medium.com/cosine-similarity-dot-product-for-normalized-vectors-c07bdb61c9d1). If nodes are similar, but not linked yet, we predict a link between them.\n",
    "\n",
    "The links are predicted on the partial network (all nodes, but 80% of the links are randomly removed) and tested on the ground truth full network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1],\n",
       "       [   0,    2],\n",
       "       [   0,    3],\n",
       "       ...,\n",
       "       [4027, 4032],\n",
       "       [4027, 4038],\n",
       "       [4031, 4038]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open link csv\n",
    "all_links = np.genfromtxt('../preprocessing/preprocessed_data/all_links.csv', delimiter=',', dtype=int)\n",
    "removed_links = np.genfromtxt('../preprocessing/preprocessed_data/removed_links.csv', delimiter=',', dtype=int)\n",
    "\n",
    "highest_node_id = all_links.max()\n",
    "all_links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_links(df):\n",
    "    # Initialize empty predicted links\n",
    "    predicted_links = []\n",
    "\n",
    "    # Iterate over all nodes and compare them to nodes they are not yet linked to\n",
    "    # Predicts link when cosine similarity > 97.5%\n",
    "    for node in range(0, highest_node_id + 1):\n",
    "        # Slices of dataframes containing the node itself\n",
    "        # and the nodes it is not connected to\n",
    "        node_df = df[df.index == node]\n",
    "        unconnected_nodes = [n for n in range(0, highest_node_id + 1) \n",
    "                             if n not in removed_links[removed_links[:,0] == node][:,1] +\n",
    "                             [node]]\n",
    "        unconnected_nodes_df = df[df.index.isin(unconnected_nodes)]\n",
    "\n",
    "        # Cosine similarity between the node itself\n",
    "        # and the nodes it is not already connected to\n",
    "        similarity_scores = cosine_similarity(node_df, unconnected_nodes_df)[0].tolist()\n",
    "        similarity_dict = dict(zip(unconnected_nodes, similarity_scores))\n",
    "            \n",
    "        # If similarity > 97.5%, append to the list of predictions\n",
    "        for pair in similarity_dict.items():\n",
    "            if pair[1] > 0.975:\n",
    "                predicted_links.append((node, pair[0]))\n",
    "\n",
    "    return predicted_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_array_to_pairs(link_array):\n",
    "    pairs = []\n",
    "\n",
    "    # Add a bidirectional pair for each link\n",
    "    # E.g. (1,0) and (0,1)\n",
    "    for link in link_array:\n",
    "        pairs.append((link[0], link[1]))\n",
    "        pairs.append((link[1], link[0]))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred):\n",
    "    # Convert the arrays to bidirectional lists of pairs for easier comparison\n",
    "    all_link_pairs = link_array_to_pairs(all_links)\n",
    "    removed_link_pairs = link_array_to_pairs(removed_links)\n",
    "\n",
    "    # False positive predictions\n",
    "    # i.e. it predicted a link that isn't there\n",
    "    fp = set(pred) - set(all_link_pairs)\n",
    "\n",
    "    # False negative predictions\n",
    "    # i.e. it didnt predict a link that should have been there\n",
    "    fn = set(all_link_pairs) - set(pred) - set(removed_link_pairs)\n",
    "\n",
    "    # True positive predictions\n",
    "    # i.e. all correct predictions\n",
    "    tp = set(pred) - fp\n",
    "\n",
    "    # True negative predictions\n",
    "    # i.e. all links that were correctly not predicted\n",
    "    all_possible_pairs = itertools.product(list(range(0, highest_node_id + 1)), list(range(0, highest_node_id + 1)))\n",
    "    tn = set(all_possible_pairs) - set(all_link_pairs) - set(pred)\n",
    "    \n",
    "    total = len(tp) + len(tn) + len(fp) + len(fn)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (len(tp) + len(tn))/total\n",
    "    \n",
    "    # Precision\n",
    "    precision = len(tp) / (len(tp) + len(fp))\n",
    "    \n",
    "    # Make confusion matrix pairs with (absolute values, percentages)\n",
    "    fp = (len(fp), len(fp)/total)\n",
    "    fn = (len(fn), len(fn)/total)\n",
    "    tp = (len(tp), len(tp)/total)\n",
    "    tn = (len(tn), len(tn)/total)\n",
    "    \n",
    "    return fp, fn, tp, tn, accuracy, precision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for Node2Vec\n",
    "\n",
    "This takes a while to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting links for dimension:  8 ...\n",
      "Node2vec dim:  8 \n",
      " fp:  (73777, 0.004538777085121649) \n",
      " fn:  (16352, 0.0010059785962550551) \n",
      " tp:  (101414, 0.006239011335653753) \n",
      " tn:  (16063276, 0.9882162329829696) \n",
      " accuracy:  0.9944552443186233 \n",
      " precision:  0.5788767687837846\n",
      "Predicting links for dimension:  16 ...\n",
      "Node2vec dim:  16 \n",
      " fp:  (12849, 0.0007930700650152037) \n",
      " fn:  (29107, 0.0017965515123665294) \n",
      " tp:  (35435, 0.0021871303411793715) \n",
      " tn:  (16124204, 0.9952232480814389) \n",
      " accuracy:  0.9974103784226183 \n",
      " precision:  0.7338870019053931\n",
      "Predicting links for dimension:  32 ...\n",
      "Node2vec dim:  32 \n",
      " fp:  (4988, 0.00030836252205923353) \n",
      " fn:  (34405, 0.0021269471875396814) \n",
      " tp:  (4308, 0.00026632432739197634) \n",
      " tn:  (16132065, 0.9972983659630091) \n",
      " accuracy:  0.9975646902904011 \n",
      " precision:  0.46342512908777966\n",
      "Predicting links for dimension:  64 ...\n",
      "Node2vec dim:  64 \n",
      " fp:  (4445, 0.00027483808203456107) \n",
      " fn:  (34810, 0.002152331526574369) \n",
      " tp:  (1296, 8.013276812526235e-05) \n",
      " tn:  (16132608, 0.9974926976232658) \n",
      " accuracy:  0.9975728303913911 \n",
      " precision:  0.22574464379028045\n",
      "Predicting links for dimension:  128 ...\n",
      "Node2vec dim:  128 \n",
      " fp:  (4387, 0.00027125620374129515) \n",
      " fn:  (34827, 0.002153416869773897) \n",
      " tp:  (1022, 6.319212223013532e-05) \n",
      " tn:  (16132666, 0.9975121348042547) \n",
      " accuracy:  0.9975753269264848 \n",
      " precision:  0.18894435200591606\n"
     ]
    }
   ],
   "source": [
    "dimensions = [8, 16, 32, 64, 128]\n",
    "\n",
    "for dim in dimensions:\n",
    "      # Import and make predictions\n",
    "      print('Predicting links for dimension: ', str(dim), '...')\n",
    "      node2vec = pd.read_csv('../node_embeddings/embedded_partial_data/node2vec_' + str(dim) + '.csv')\n",
    "      node2vec_pred = predict_links(node2vec)\n",
    "\n",
    "      # Obtain and print metrics\n",
    "      fp, fn, tp, tn, accuracy, precision = metrics(node2vec_pred)\n",
    "      print('Node2vec dim: ', str(dim), '\\n',\n",
    "            'fp: ', fp, '\\n',\n",
    "            'fn: ', fn, '\\n',\n",
    "            'tp: ', tp, '\\n',\n",
    "            'tn: ', tn, '\\n',\n",
    "            'accuracy: ', accuracy, '\\n',\n",
    "            'precision: ', precision)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
